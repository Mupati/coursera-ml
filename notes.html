<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Notes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: 29d1c5bc36da364ad5aa86946d420b7bbc54a253 */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<h1>Notes for Machine Learning</h1>
<p>This is my notes for the <a href="http://class.coursera.org/ml-003/">Machine Learning course</a> given by <a href="http://ai.stanford.edu/~ang/">Andrew Ng</a> on <a href="http://www.coursera.org">Coursera</a>.</p>
<h2>Introduction</h2>
<h3>What is Machine Learning?</h3>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some task T and performance measure P, if its performance on T, as measured by P, improves with experience E. - Tom Mitchell</p>
</blockquote>
<p>In email spam filtering program, <strong>T</strong> is to classify emails as spams or not spams. <strong>P</strong> is the number of emails correctly classified as spams or not spams. <strong>E</strong> is watching you label emails as spams or not spams.</p>
<h3>Machine Learning Algorithms</h3>
<ul>
<li><strong>Supervised Learning</strong>: you teach the program</li>
<li><strong>Unsupervised Learning</strong>: the program learn by itself</li>
<li>Reinforcement Learning</li>
<li>Recommender Systems</li>
</ul>
<p>Also talk about: Practical advice for applying learning algorithms.</p>
<h2>Classification</h2>
<p>Example:</p>
<ul>
<li>Email: Spam / Not Spam?</li>
<li>Online Transactions: Fraudulent (Yes / No)?</li>
<li>Tumor: Malignant / Benign ?</li>
</ul>
<p><strong>Binary Classification problem</strong>: \( y \in \{0, 1\} \) where</p>
<ul>
<li>0: Negative Class (malignant tumor)</li>
<li>1: Postive Class (benign tumor)</li>
</ul>
<p><strong>Multi-class Classification problem</strong>: \( y \in \{0, 1, 2, 3...\} \)</p>
<ul>
<li>If \( h_{\theta}(x) &gt; 0.5 \), \( y = 1 \)</li>
<li>If \( h_{\theta}(x) &lt; 0.5 \), \( y = 0 \)</li>
</ul>
<h2>Logistic Regression</h2>
<p>Recall Linear Regression Model funciton: \( h_{\theta}(x) = \theta^{T}x \)</p>
<p>\( h_{\theta}(x) = g(\theta^{T}x) \) where \( g(z) = \frac{1}{1 + e^{-z}} \), so
\( h_{\theta}(x) = \frac{1}{1 + e^{-\theta^{T}x}} \).</p>
<h3>Interpretation of Hypothesis Output</h3>
<ul>
<li>\( h_{\theta}(x) = \) estimated probabilities that \( y = 1 \) on input \( x \).</li>
<li>\( h_{\theta}(x) = P (y = 1 | x; \theta) \) is interpreted as:
probability that \( y = 1 \), given \( x \) parameterized by \( \theta \)</li>
</ul>
<p>Since \( P(y = 0 | x; \theta) + P(y = 1 | x; \theta) = 1 \), we have \[ P(y = 0 | x; \theta) = 1 - P(y = 1 | x; \theta) = 1 - h_{\theta}(x) = 1 - \frac{1}{1 + e^{-\theta^{T}x}} \]</p>
<h3>Non-linear Decision Boundaries</h3>
<p>\[ h_{\theta}(x) = g(\theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{1}^{2} + \theta_{4}x_{2}^{2}) \]</p>
<p>Let \( \theta\ = \begin{bmatrix} -1 \\ 0 \\ 0 \\ 1 \\ 1 \end{bmatrix} \), we have \( h_{\theta}(x) = g(-1 + x_{1}^{2} + x_{2}^{2}) \), which predicts \( y = 1 \) if \( -1 + x_{1}^{2} + x_{2}^{2} \geq 0 \).</p>
<h3>Cost Function</h3>
<p>For Linear Regression, the Cost Function is a squared cost function:
\[ \text{Cost}(h_{\theta}(x, y)) = \frac{1}{2}(h_{\theta}(x) - y)^{2} \]</p>
<p>For Logistic Regression, the Cost Function is:
\[ \text{Cost}(h_{\theta}(x, y)) = \begin{cases} -\log{h_{\theta}(x)} &amp; \text{if} \; y = 1 \\
-\log{(1-h_{\theta}(x))} &amp; \text{if} \; y = 0 \end{cases} \]</p>
<p>Recall we have \( J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \text{Cost}(h_{\theta}(x^{(i)}), y^{(i)}) \) and \( y \in \{0, 1\} \).</p>
<h3>Gradient Descent</h3>
<p>Cost Function in one equation:
\[ \text{Cost}(h_{\theta}(x, y)) = -y \log{h_{\theta}(x)} + - (1 - y) \log{(1-h_{\theta}(x))} \]</p>
<p>Thus we have
\[ J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \text{Cost}(h_{\theta}(x^{(i)}), y^{(i)}) = - \frac{1}{m} \left[\sum_{i=1}^{m}y^{(i)} \log{h_{\theta}(x^{(i)})} + (1 - y^{(i)}) \log{(1-h_{\theta}(x^{(i)}))} \right] \]</p>
<p>We will \( \min_{\theta}J(\theta) \) and output \( h_{\theta}(x) = \frac{1}{1 + e^{-\theta^{T}x}} \), so we do</p>
<p>Repeat \( \{ \)
\[ \theta_{j} := \theta_{j} - \alpha \frac{\partial}{\partial \theta_{j}}J(\theta) \qquad (j = 0, 1, 2, 3, ..., n) \]
\( \} \)
and \[ \frac{\partial}{\partial \theta_{j}}J(\theta) = \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} \] which is identical to the algorithm of linear regression! The difference is the definition of hypothesis \[ h_{\theta}(x) = \begin{cases} \theta^{T}x &amp; \text{for linear regression} \\ \frac{1}{1 + e^{-\theta^{T}x}} &amp; \text{for logistic regression} \end{cases} \].</p>
<h3>Advanced Optimization</h3>
<ul>
<li>Gradient descent</li>
<li>Conjugate gradient</li>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
<p>Advantages:</p>
<ul>
<li>No need to manually pick \( \alpha \). They perform a linear search for all possible \( \alpha \)</li>
<li>Often faster than gradient descent</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>More complex: you should not implement these algorithms by yourself, and if you do, use function to calculate inverse of matrix. Make sure to try different libraries of different implementations</li>
</ul>
<h3>Multi-class Classification: One-vs-all</h3>
<p>Example:</p>
<ul>
<li>Email foldering/tagging: Work, Friends, Family, Hobby</li>
<li>Medical diagrams: Not ill, Cold, flu</li>
<li>Weather: Sunny, Cloudy, Rain, Snow</li>
</ul>
<p>We have \( h_{\theta}^{(1)}(x) \) for the first class, \( h_{\theta}^{(2)}(x) \) for the second class and so one for all classes. So we calculate
\[ h_{\theta}^{(i)}(x) = P(y=i|x;\theta) \qquad (i = 1, 2, 3) \]</p>
<p>On a new input \( x \), to make a prediction, pick the class \( i \) that maximizes the hypothesis \[ \max_{i}h_{\theta}^{(i)}(x) \]</p>
<h2>Regularization</h2>
<p>The problem of over-fitting</p>
<p>For linear regression, we can have
\[ h_{\theta}(x) = \begin{cases} \theta_{0} + \theta_{1}x &amp; \text{underfit} &amp; \text{high bias} \\ \theta_{0} + \theta_{1}x + \theta_{2}x^{2} &amp; \text{just right} \\ \theta_{0} + \theta_{1}x + \theta_{2}x^{2} + \theta_{3}x^{3} + \theta_{4}x^{4} &amp; \text{overfit} &amp; \text{high variance} \end{cases} \]</p>
<ul>
<li>High Bias: </li>
<li>High variance: </li>
</ul>
<h3>Addressing Overfitting</h3>
<p>Options:</p>
<ol>
<li>
Reduce number of features
<ul>
<li>Manually select which features to keep</li>
<li>Model selection algorithm</li>
</ul>
</li>
<li>
Regularization
<ul>
<li>Keep all the features, but reduce magnitude/values of parameters \( \theta_{j} \)</li>
<li>Works well when we have a lot of features, each of which contributes a bit to predicting \( y \).</li>
</ul>
</li>
</ol>
<h3>Cost Function for Regularization</h3>
<p>Small values for parameters \( \theta_{0}, \theta_{1}, ..., \theta_{n} \)</p>
<ul>
<li>&quot;Simpler&quot; hypothesis</li>
<li>Less prone to overfitting</li>
</ul>
<p>We penalize all parameters by adding extra term in cost function:
\[ J(\theta) = \frac{1}{2m} \left[ \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^{2} + \lambda \sum_{j=1}^{n} \theta_{j}^{2} \right] \]
in which we usually don't penalize \( \theta_{0} \). \( \lambda \) controls the tradeoff between the goal of fitting the training set well and the goal of keeping the parameters small and thus keeping the hypothesis relatively simple to avoid overfitting.</p>
<p>If \( \lambda \) is chosen as a very large number, then all the parameters \( \theta_{1}, \theta_{2}, ... \theta_{n} \) will be penalized to close to 0, thus the hypothesis is almost equal to \( h_{\theta}(x) = \theta_{0} \), which will underfit the training set.</p>
<h3>Regularized Linear Regression</h3>
<p>For Gradient Descent:</p>
<p>Repeat: \( \{ \)
\[ \begin{aligned} &amp; \theta_{0} := \theta_{0} - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)} \\ &amp; \theta_{j} := \theta_{j} - \alpha \left[ \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \frac{\lambda}{m} \theta_{j} \right] \\ &amp; \qquad\qquad\qquad (j = 1, 2, 3, ..., n) \end{aligned} \]
\( \} \) in which we can derive:
\[ \theta_{j} := \theta_{j}(1 - \alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} \]
where \( 1 - \alpha \frac{\lambda}{m} \) is always a number small than 1 which will shrink \( \theta_{j} \) in each iteration.</p>
<p>For Normal Equation:</p>
<p>\[ \theta = \left(X^{T}X + \lambda \begin{bmatrix}
0 \\ 
&amp; 1  \\ 
&amp; &amp; \ddots \\
&amp; &amp; &amp; 1
\end{bmatrix} \right) ^{-1}  X^{T}y \]</p>
<p>Note suppose \( m \leq n \), \( X^{T}X \) is non-invertible/singular, but with regularization, if \( \lambda &gt; 0 \), \( \left(X^{T}X + \lambda \begin{bmatrix}
0 \\ 
&amp; 1  \\ 
&amp; &amp; \ddots \\
&amp; &amp; &amp; 1
\end{bmatrix} \right) \) is non-singular and thus invertible.</p>
<h3>Regularized Logistic Regression</h3>
<p>jVal = \[ J(\theta) = \left[- \frac{1}{m} \sum_{i=1}^{m}y^{(i)} \log{h_{\theta}(x^{(i)})} + (1 - y^{(i)}) \log{(1-h_{\theta}(x^{(i)}))} \right] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_{j}^{2} \]</p>
<p>gradient(1) = \[ \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)} \]</p>
<p>gradient(2) = \[ \left( \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_{1}^{(i)} \right) + \frac{\lambda}{m} \theta_{1} \]</p>
<p>gradient(n+1) = \[ \left( \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_{n}^{(i)} \right) + \frac{\lambda}{m} \theta_{n} \]</p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
